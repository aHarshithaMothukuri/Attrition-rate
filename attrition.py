# -*- coding: utf-8 -*-
"""attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1if7BEMzB5bQ6F4tN1mkr6dPHaOTqGPCa
"""

import pandas as pd
import numpy as np

df = pd.read_csv("hr.csv") 
df.head()



dept = np.unique(df['department'])
dept

sal = np.unique(df['salary'])
sal

feats = ['department','salary']
dp_final = pd.get_dummies(df,columns=feats,drop_first=True)
dp_final

from sklearn.model_selection import train_test_split

x = dp_final.drop(['left'],axis=1).values
y = dp_final['left'].values

! pip install tensorflow

x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.3)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test= sc.transform(x_test)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()

classifier.add(Dense(9, kernel_initializer = "uniform",activation = "relu",input_dim=18))

classifier.add(Dense(1, kernel_initializer = "uniform",activation = "sigmoid"))

classifier.compile(optimizer ="adam",loss ="binary_crossentropy",metrics=["accuracy"])

import time
a = [10,20,30,40,50,60]
for i in a :
    start = time.time()
    classifier.fit(x_train,y_train,batch_size = i,epochs=10)
    end = time.time()
    print(end - start)
    print (i)

y_pred = classifier.predict(x_test)
y_pred

y_pred = (y_pred>0.5)

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_pred)

cm

new_pred=classifier.predict(sc.transform(np.array([[0.26,0.7,3.,238.,6.,0.,0.,0.,0.,0.,0.,0.,0.,0.,1.,0.,0.,1.]])))

new_pred =(new_pred >0.5)
new_pred

new_pred =(new_pred >0.6)
new_pred

from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score

def make_classifier():
  classifier = Sequential()
  classifier.add(Dense(9, kernel_initializer = "uniform",activation ="relu",input_dim =18))
  classifier.add(Dense(1, kernel_initializer = "uniform",activation ="sigmoid"))
  classifier.compile(optimizer ="adam",loss ="binary_crossentropy",metrics=["accuracy"])
  return classifier

classifier = KerasClassifier(build_fn=make_classifier,batch_size =10,nb_epoch =1)

accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train,cv= 10)

mean = accuracies.mean()
mean

variance = accuracies.var()
variance

from keras.layers import Dropout

classifier = Sequential()
classifier.add(Dense(9, kernel_initializer = "uniform",activation ="relu",input_dim =18))
classifier.add(Dropout(rate = 0.1))
classifier.add(Dense(1, kernel_initializer = "uniform",activation ="sigmoid"))
classifier.compile(optimizer ="adam",loss ="binary_crossentropy",metrics=["accuracy"])

from sklearn.model_selection import GridSearchCV
def make_classifier(optimizer):
  classifier = Sequential()
  classifier.add(Dense(9, kernel_initializer = "uniform",activation ="relu",input_dim =18))
  classifier.add(Dense(1, kernel_initializer = "uniform",activation ="sigmoid"))
  classifier.compile(optimizer ="adam",loss ="binary_crossentropy",metrics=["accuracy"])
  return classifier

classifier = KerasClassifier(build_fn = make_classifier)

params = {
    'batch_size' : [20,35],
    'epochs': [2,3],
    'optimizer':['adam','rmsprop']
}

grid_search =GridSearchCV(estimator =classifier,param_grid =params,scoring ='accuracy',cv=2)

grid_search = grid_search.fit(x_train,y_train)

best_param = grid_search.best_params_
best_accuracy = grid_search.best_score_

best_param

best_accuracy

